---
description: Analyze codebase for compute inefficiencies common in AI research
argument-hint: "[path]"
allowed-tools: Glob, Read, Write, Task
---

# Compute Efficiency Analysis

Analyze Python codebase for compute inefficiencies common in AI/ML research workflows.

## Phase 1: Discover Files

Determine the target directory:
- If `$ARGUMENTS` is provided, use that path
- Otherwise, use the current working directory

Use Glob to find all Python files and Jupyter notebooks:
- Pattern: `**/*.py` in target directory
- Pattern: `**/*.ipynb` in target directory

Count the files found. If no Python or notebook files are found:
- Report to the user: "No Python or Jupyter notebook files found in [directory]. Nothing to analyze."
- Stop execution - do not create a report file.

## Phase 2: Load Anti-Pattern Catalog

Read the compute anti-pattern catalog for reference:

@${CLAUDE_PLUGIN_ROOT}/references/compute-antipatterns.md

This catalog contains known inefficiency patterns organized by category with detection heuristics and fixes.

## Phase 3: Spawn Analysis Agent

Use the Task tool to spawn an analysis agent with subagent_type "general-purpose".

Provide the agent with:
1. The list of Python files and notebooks found in Phase 1
2. The anti-pattern catalog content from Phase 2
3. The report format specification below

**Agent prompt:**

```
You are a compute efficiency analyst for AI research codebases. Your task is to identify inefficiencies that waste GPU/compute resources.

## Files to Analyze
[Include the file list from Phase 1]

## Anti-Pattern Reference
[Include the catalog content from Phase 2]

## Your Task

1. Read each Python file and Jupyter notebook
2. For each file, check for anti-patterns from the catalog
3. For each issue found, record:
   - File path and line number(s)
   - Anti-pattern category and ID
   - Severity (Critical / High / Medium / Low)
   - Problem description (what's wrong and why it matters)
   - The problematic code snippet
   - Suggested fix with corrected code
   - Confidence level (High / Medium / Low)

4. Estimate VRAM requirements:
   - Look for model loading patterns (AutoModel.from_pretrained, torch.load, etc.)
   - Identify model names/sizes from the code
   - Use the VRAM estimation table from the catalog
   - Note the precision being used (FP32, BF16, FP16)

## Quality Guidelines

- Only report issues with Medium or High confidence
- Prioritize Critical and High severity issues
- Provide actionable, specific fixes with code
- Don't invent issues to seem thorough - if code is clean, say so
- Distinguish between definite issues and potential optimizations
- Note when a pattern might be intentional (e.g., FP32 kept for numerical stability)

## Output

Write the report to a file named: efficiency_report_[TODAY'S DATE].md

Use today's date in yyyy-mm-dd format (e.g., efficiency_report_2024-01-15.md).

Use this report format:

---

# Compute Efficiency Analysis Report

**Generated:** [date]
**Directory analyzed:** [path]
**Files analyzed:** X Python files, Y Jupyter notebooks

---

## Resource Estimation Summary

**Detected workflow:** [inference / training / activation collection / probing / etc.]

**Models detected:**
- [model-name]: ~[X]GB VRAM ([precision])

**Estimated minimum VRAM:** [X]GB
**Recommended VRAM (with overhead):** [X]GB

---

## Issues Found

### Critical Issues ([count] found)

#### [Brief title]

**Location:** `path/to/file.py:123-125`
**Category:** [Category name]
**Confidence:** [High/Medium]

**Problem:**
[Clear explanation of what's inefficient and the concrete impact]

**Current code:**
```python
[the problematic code]
```

**Suggested fix:**
```python
[the corrected code]
```

---

### High Severity Issues ([count] found)

[Same format as Critical]

### Medium Severity Issues ([count] found)

[Same format]

### Low Severity Issues ([count] found)

[Same format]

---

## Summary Recommendations

**Priority fixes (highest impact first):**
1. [Most impactful fix] - [estimated benefit]
2. [Second most impactful] - [estimated benefit]
3. [Third] - [estimated benefit]

**Estimated total impact:**
- Memory reduction: ~[X]GB (if applicable)
- Speed improvement: ~[X]x (if applicable)

---

*Report generated by /efficiency-check command*

---

If no significant issues are found, still write the report but note that the codebase appears well-optimized, and mention any minor suggestions or best practices that could be considered.
```

## Phase 4: Confirm Completion

After the agent completes, confirm to the user:
- The report file location
- Summary of issues found (counts by severity)
- Top recommendation if any critical issues were found
